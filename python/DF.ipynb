{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://spark.apache.org/docs/2.3.1/api/python/pyspark.sql.html#pyspark-sql-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame') \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/anaconda3/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'ipython3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tworzenie DataFrame'u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './SparkSQLdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# json\n",
    "people = spark.read.json(data_path+'people.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "|  35|   Emma|\n",
      "|null|   null|\n",
      "|  31|   null|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv\n",
    "people_txt = spark.read.option(\"inferSchema\", \"true\").csv(data_path+'people.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|    _c0| _c1|\n",
      "+-------+----+\n",
      "|Michael|29.0|\n",
      "|   Andy|30.0|\n",
      "| Justin|19.0|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_txt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolekcja Row'ów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPerson1 = Row(name='Greg', age=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=32, name='Greg')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPerson1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greg'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPerson1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPerson1.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPerson1['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'age' in newPerson1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPerson = Row(\"age\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPerson2 = newPerson(24, 'Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=24, name='Alice')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPerson2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPerson3 = newPerson(None, None)\n",
    "newPerson4 = newPerson(33, None)\n",
    "newPerson5 = newPerson(None, 'Peter')\n",
    "newPerson6 = newPerson(32, 'Peter')\n",
    "newPerson7 = newPerson(40, 'Greg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPeopleDF = spark.createDataFrame([newPerson1, newPerson2, newPerson3, newPerson4, \n",
    "                                     newPerson5, newPerson6, newPerson7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age| name|\n",
      "+----+-----+\n",
      "|  32| Greg|\n",
      "|  24|Alice|\n",
      "|null| null|\n",
      "|  33| null|\n",
      "|null|Peter|\n",
      "|  32|Peter|\n",
      "|  40| Greg|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inne lokalne kolekcje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typy danych: http://spark.apache.org/docs/2.3.1/api/python/pyspark.sql.html#module-pyspark.sql.types\n",
    "\n",
    "Kilka podstawowych: IntegerType, DoubleType, FloatType, StringType, BooleanType, NullType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definicja schematu\n",
    "# StructType ~ Row\n",
    "schema = StructType([StructField(\"V1\", IntegerType()), StructField(\"V2\", StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lokalna kolekcja - lista list\n",
    "df = spark.createDataFrame([[1,2],[3,4]], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| V1| V2|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "|  3|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przechodzenie RDD <-> DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "|  35|   Emma|\n",
      "|null|   null|\n",
      "|  31|   null|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'),\n",
       " Row(age=30, name='Andy'),\n",
       " Row(age=19, name='Justin'),\n",
       " Row(age=35, name='Emma'),\n",
       " Row(age=None, name=None),\n",
       " Row(age=31, name=None)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF -> RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(people.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'),\n",
       " Row(age=30, name='Andy'),\n",
       " Row(age=19, name='Justin'),\n",
       " Row(age=35, name='Emma'),\n",
       " Row(age=None, name=None),\n",
       " Row(age=31, name=None)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 'Michael'),\n",
       " (30, 'Andy'),\n",
       " (19, 'Justin'),\n",
       " (35, 'Emma'),\n",
       " (None, None),\n",
       " (31, None)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.rdd.map(tuple).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD -> DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "|  35|   Emma|\n",
      "|null|   null|\n",
      "|  31|   null|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.rdd.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|  _1|     _2|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "|  35|   Emma|\n",
      "|null|   null|\n",
      "|  31|   null|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.rdd.map(tuple).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|  0|  1|\n",
      "|  1|  2|\n",
      "|  2|  3|\n",
      "|  3|  4|\n",
      "|  4|  5|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.parallelize([(x, x+1) for x in range(5)]).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  0|  1|\n",
      "|  1|  2|\n",
      "|  2|  3|\n",
      "|  3|  4|\n",
      "|  4|  5|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do toDF można podać schemat\n",
    "schema = StructType([StructField(\"A\", IntegerType()), StructField(\"B\", StringType())])\n",
    "sc.parallelize([(x, x+1) for x in range(5)]).toDF(schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(A=0, B='1')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([(x, x+1) for x in range(5)]).toDF(schema).collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Na dwa sposoby stwórz DataFrame z 3 wierszami i 3 kolumnami - dwie typu string, jedna numeryczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| S1| S2| I1|\n",
      "+---+---+---+\n",
      "|  0|  1|  2|\n",
      "|  1|  2|  3|\n",
      "|  2|  3|  4|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema1 = StructType([StructField(\"S1\", StringType()), StructField(\"S2\", StringType()), StructField(\"I1\", IntegerType())])\n",
    "sc.parallelize([(x, x+1, x+2) for x in range(3)]).toDF(schema1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| s1| s2| i1|\n",
      "+---+---+---+\n",
      "|  a|  b|  2|\n",
      "|  c|  D|  3|\n",
      "|  E|  f|  5|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "constr = Row(\"s1\",\"s2\",\"i1\")\n",
    "r1 = constr(\"a\",\"b\",2)\n",
    "r2 = constr(\"c\",\"D\",3)\n",
    "r3 = constr(\"E\",\"f\",5)\n",
    "spark.createDataFrame([r1,r2,r3]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Z podanego RDD utwórz DataFrame z nazwanymi kolumnami `name` i `age` oraz odpowiednimi typami (string i int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michael, 29', 'Andy, 30', 'Justin, 19']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRDD = sc.textFile(data_path+\"people.txt\")\n",
    "myRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD.map(lambda x: x.split(\", \")).collect()\n",
    "schema2 = StructType([StructField(\"Name\", StringType()), StructField(\"Age\", IntegerType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## wszystko w stringach\n",
    "#myRDD.map(lambda x: x.split(\", \")).toDF().printSchema()\n",
    "\n",
    "myRDD.map(lambda x: x.split(\", \")).map(lambda x: (x[0], int(x[1]))).toDF(schema2).printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praca z DataFrame'ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ogolne wiadomosci na temat danych\n",
    "printSchema, show, columns, dtypes <br>\n",
    "Znane z RDD np: count, take, head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_txt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|    _c0| _c1|\n",
      "+-------+----+\n",
      "|Michael|29.0|\n",
      "+-------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_txt.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "+----+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba wierszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista kolumn wraz z typami danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'bigint'), ('name', 'string')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPeopleDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odwolania do poszczegolnych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'age'>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'age'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'age'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodanie/usuniecie kolumny\n",
    "withColumn, drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+\n",
      "| age|   name|ageNextYear|\n",
      "+----+-------+-----------+\n",
      "|null|Michael|       null|\n",
      "|  30|   Andy|         31|\n",
      "|  19| Justin|         20|\n",
      "|  35|   Emma|         36|\n",
      "|null|   null|       null|\n",
      "|  31|   null|         32|\n",
      "+----+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.withColumn(colName = 'ageNextYear', col = people.age +1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|   Andy|\n",
      "| Justin|\n",
      "|   Emma|\n",
      "|   null|\n",
      "|   null|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.drop('age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmiany nazwy kolumny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people_txt = people_txt.withColumnRenamed('_c0', 'name').withColumnRenamed('_c1', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|Michael|29.0|\n",
      "|   Andy|30.0|\n",
      "| Justin|19.0|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_txt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podstawowe statystyki kolumn w DataFrame'ie.\n",
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+\n",
      "|summary|              age|   name|\n",
      "+-------+-----------------+-------+\n",
      "|  count|                4|      4|\n",
      "|   mean|            28.75|   null|\n",
      "| stddev|6.849574196011505|   null|\n",
      "|    min|               19|   Andy|\n",
      "|    max|               35|Michael|\n",
      "+-------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|              age|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|            28.75|\n",
      "| stddev|6.849574196011505|\n",
      "|    min|               19|\n",
      "|    max|               35|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.describe('age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Braki danych\n",
    "isNull, isNotNull<br>\n",
    "fillna, dropna, replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age| name|\n",
      "+----+-----+\n",
      "|  32| Greg|\n",
      "|  24|Alice|\n",
      "|null| null|\n",
      "|  33| null|\n",
      "|null|Peter|\n",
      "|  32|Peter|\n",
      "|  40| Greg|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age| name|\n",
      "+----+-----+\n",
      "|null| null|\n",
      "|null|Peter|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.filter(newPeopleDF.age.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 32| Greg|\n",
      "| 24|Alice|\n",
      "| 33| null|\n",
      "| 32|Peter|\n",
      "| 40| Greg|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.filter(newPeopleDF.age.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 32| Greg|\n",
      "| 24|Alice|\n",
      "| -1| null|\n",
      "| 33| null|\n",
      "| -1|Peter|\n",
      "| 32|Peter|\n",
      "| 40| Greg|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.fillna(-1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 32|   Greg|\n",
      "| 24|  Alice|\n",
      "| -1|unknown|\n",
      "| 33|unknown|\n",
      "| -1|  Peter|\n",
      "| 32|  Peter|\n",
      "| 40|   Greg|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.fillna({'age':-1, 'name':'unknown'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age| name|\n",
      "+----+-----+\n",
      "|  32| Greg|\n",
      "|  24|Alice|\n",
      "|null|   NN|\n",
      "|  33|   NN|\n",
      "|null|Peter|\n",
      "|  32|Peter|\n",
      "|  40| Greg|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.fillna({'name':'unknown'}).replace('unknown', 'NN').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 32| Greg|\n",
      "| 24|Alice|\n",
      "| 32|Peter|\n",
      "| 40| Greg|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 32| Greg|\n",
      "| 24|Alice|\n",
      "| 33| null|\n",
      "| 32|Peter|\n",
      "| 40| Greg|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeopleDF.dropna(subset='age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje wprost ze skladni SQL \n",
    "select, where (alias filter), orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "|  35|   Emma|\n",
      "|null|   null|\n",
      "|  31|   null|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|Justin| 19|\n",
      "|  Andy| 30|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.\\\n",
    "select('name', 'age').\\\n",
    "where(people.name.like('%n%')).\\\n",
    "orderBy(people.age.asc()).\\\n",
    "show()\n",
    "# select: wyswietl kolumny 'name' i 'age'\n",
    "# where: uwzglednij tylko imiona (name) zaweirajace litere 'n'\n",
    "# orderBy: zbior posortuj rosnaco po kolumnie 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|  name|\n",
      "+---+------+\n",
      "| 19|Justin|\n",
      "| 30|  Andy|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gdy chcemy zobaczyć wszystkie kolumny select jest zbędny\n",
    "people.\\\n",
    "where(people.name.like('%n%')).\\\n",
    "orderBy(people.age.asc()).\\\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Wyswietl imiona ludzi ze zbioru `people` starszych niz 29 lat. Wyniki posortuj alfabetycznie po kolumnie name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacje na zbiorach\n",
    "union - dziala jak UNION ALL w SQL. <br>\n",
    "intersect (INTERSECT z SQLa), subtract (EXCEPT z SQLa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "|  35|   Emma|\n",
      "|null|   null|\n",
      "|  31|   null|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|Michael|29.0|\n",
      "|   Andy|30.0|\n",
      "| Justin|19.0|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_txt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|    age|   name|\n",
      "+-------+-------+\n",
      "|   null|Michael|\n",
      "|     30|   Andy|\n",
      "|     19| Justin|\n",
      "|     35|   Emma|\n",
      "|   null|   null|\n",
      "|     31|   null|\n",
      "|Michael|   29.0|\n",
      "|   Andy|   30.0|\n",
      "| Justin|   19.0|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.union(people_txt).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|30.0|   Andy|\n",
      "|19.0| Justin|\n",
      "|35.0|   Emma|\n",
      "|null|   null|\n",
      "|31.0|   null|\n",
      "|29.0|Michael|\n",
      "|30.0|   Andy|\n",
      "|19.0| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.union(people_txt.select(people.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################\n",
    "\n",
    "# Zadania 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './SparkSQLdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people = spark.read.json(data_path+'people.json')\n",
    "employees = spark.read.json(data_path+'employees.json')\n",
    "people_txt = spark.read.option(\"inferSchema\", \"true\").csv(data_path+'people.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPerson1 = Row(name=u'Greg', age=32)\n",
    "newPerson = Row(\"age\", \"name\")\n",
    "newPerson2 = newPerson(24, 'Alice')\n",
    "newPerson3 = newPerson(None, None)\n",
    "newPerson4 = newPerson(33, None)\n",
    "newPerson5 = newPerson(None, 'Peter')\n",
    "newPerson6 = newPerson(32, 'Peter')\n",
    "newPerson7 = newPerson(40, 'Greg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPeopleDF = spark.createDataFrame([newPerson1, newPerson2, newPerson3, newPerson4, \n",
    "                                     newPerson5, newPerson6, newPerson7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people_txt = people_txt.withColumnRenamed('_c0', 'name').withColumnRenamed('_c1', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPeople = spark.read.parquet(data_path+'allPeople.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wyswietl imiona ludzi ze zbioru `people`, o ktorych wielku nie mamy informacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|   null|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.where(people.age.isNull()).select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Na koniec zbioru `people` doklej zbiór `newPeopleDF` oraz `people_txt`. Tak utworzony DataFrame nazwij `allPeople`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = people.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|30.0|   Andy|\n",
      "|19.0| Justin|\n",
      "|35.0|   Emma|\n",
      "|null|   null|\n",
      "|31.0|   null|\n",
      "|32.0|   Greg|\n",
      "|24.0|  Alice|\n",
      "|null|   null|\n",
      "|33.0|   null|\n",
      "|null|  Peter|\n",
      "|32.0|  Peter|\n",
      "|40.0|   Greg|\n",
      "|29.0|Michael|\n",
      "|30.0|   Andy|\n",
      "|19.0| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allPeople = people.union(newPeopleDF.select(cols)).union(people_txt.select(cols))\n",
    "allPeople.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Wybierz ze zbioru `allPeople` te wiersze, ktore wystepuja rowniez w zbiorze `people`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|32.0|  Peter|\n",
      "|24.0|  Alice|\n",
      "|29.0|Michael|\n",
      "|40.0|   Greg|\n",
      "|33.0|   null|\n",
      "|null|  Peter|\n",
      "|32.0|   Greg|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wybierz ze zbioru `allPeople` te imiona, ktore NIE wystepuja w zbiorze `people_txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "| Greg|\n",
      "|Alice|\n",
      "| Emma|\n",
      "|Peter|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allPeople.select(\"name\").subtract(people_txt.select(\"name\")).dropna().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Usun ze zbioru `allPeople` wiersze, ktore zawieraja same braki danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|30.0|   Andy|\n",
      "|19.0| Justin|\n",
      "|35.0|   Emma|\n",
      "|31.0|   null|\n",
      "|32.0|   Greg|\n",
      "|24.0|  Alice|\n",
      "|33.0|   null|\n",
      "|null|  Peter|\n",
      "|32.0|  Peter|\n",
      "|40.0|   Greg|\n",
      "|29.0|Michael|\n",
      "|30.0|   Andy|\n",
      "|19.0| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allPeople.dropna(\"all\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Do zbioru `allPeople` dodaj kolumne 'age' zawierajaca wiek powiekszony o 1. Zmien nazwe oryginalnej kolumny 'age' na 'starting_age'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|starting_age|   name|\n",
      "+------------+-------+\n",
      "|        null|Michael|\n",
      "|        30.0|   Andy|\n",
      "|        19.0| Justin|\n",
      "|        35.0|   Emma|\n",
      "|        null|   null|\n",
      "|        31.0|   null|\n",
      "|        32.0|   Greg|\n",
      "|        24.0|  Alice|\n",
      "|        null|   null|\n",
      "|        33.0|   null|\n",
      "|        null|  Peter|\n",
      "|        32.0|  Peter|\n",
      "|        40.0|   Greg|\n",
      "|        29.0|Michael|\n",
      "|        30.0|   Andy|\n",
      "|        19.0| Justin|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allPeople = allPeople.withColumnRenamed(\"age\",\"starting_age\")\n",
    "allPeople.withColumn(\"age\", allPeople.starting_age + 1)\n",
    "allPeople.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Ile unikatowych rekordow znajduje sie w zbiorze `allPeople`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPeople.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **⋆** Do zbioru `employees` dodaj kolumny: z pensjami po 0-10% podwyżce (dla każdego losowo z rozkładu jednostajnego) oraz z różnicą pomiędzy pensją przed i po podwyżce. Zbiór posortuj alfabetycznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|Michael|  3000|\n",
      "|   Andy|  4500|\n",
      "| Justin|  3500|\n",
      "|  Berta|  4000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+------------------+\n",
      "|   name|salary|         salar_inc|       salary_diff|\n",
      "+-------+------+------------------+------------------+\n",
      "|   Andy|  4500| 4944.037338866702| 444.0373388667023|\n",
      "|  Berta|  4000| 4335.627127745331|335.62712774533077|\n",
      "| Justin|  3500|3787.3371536584673| 287.3371536584678|\n",
      "|Michael|  3000|3150.8860324144957| 150.8860324144958|\n",
      "+-------+------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees.withColumn(\"salar_inc\", employees.salary * (f.rand(123)/10 + 1))\\\n",
    ".withColumn(\"salary_diff\", employees.salary * f.rand(123)/10).orderBy(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praca z DataFrame'ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './SparkSQLdata/'\n",
    "people = spark.read.json(data_path+'people.json')\n",
    "employees = spark.read.json(data_path+'employees.json')\n",
    "people_txt = spark.read.option(\"inferSchema\", \"true\").csv(data_path+'people.txt')\n",
    "newPeople = spark.read.parquet(data_path+'newPeople.parquet')\n",
    "people_txt = people_txt.withColumnRenamed('_c0', 'name').withColumnRenamed('_c1', 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(age)|\n",
      "+--------+\n",
      "|      19|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.select(f.min(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|min_age|\n",
      "+-------+\n",
      "|     19|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.select(f.min(\"age\").alias(\"min_age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------------+\n",
      "| age|   name|             random|\n",
      "+----+-------+-------------------+\n",
      "|null|Michael| 0.4085363219031828|\n",
      "|  30|   Andy| 0.8811793095417685|\n",
      "|  19| Justin| -2.013921870967947|\n",
      "|  35|   Emma| 1.6641751435679302|\n",
      "|null|   null|-1.0878600404148453|\n",
      "|  31|   null| 1.1432831717404852|\n",
      "+----+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.withColumn(\"random\", f.randn(42)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------------------+\n",
      "| age|   name|              random|\n",
      "+----+-------+--------------------+\n",
      "|null|Michael|                null|\n",
      "|  30|   Andy|1.068647458152446...|\n",
      "|  19| Justin|1.7848230096318725E8|\n",
      "|  35|   Emma|1.586013452313430...|\n",
      "|null|   null|                null|\n",
      "|  31|   null|2.904884966524742...|\n",
      "+----+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.withColumn(\"random\", f.exp(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join\n",
    "inner (domyslny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|   name| age|salary|\n",
      "+-------+----+------+\n",
      "|Michael|null|  3000|\n",
      "|   Andy|  30|  4500|\n",
      "| Justin|  19|  3500|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.join(other=employees, on='name', how='inner').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Uwaga ogólna </b><br>\n",
    "Join to stosunkowo popularna, ale kosztowna operacja.<br>\n",
    "W sytuacji, kiedy jeden z łaczonych DataFramow jest znacznie mniejszy (w szczegolnosci na tyle mały, że w całości mieści się w pamięci), zaleca sie zastosowanie <i>broadcast hash join</i>.<br>\n",
    "(Mała tabela zostanie zebrana do pamięci i wysłana do każdego noda).<br>\n",
    "W niektórych przypadkach optymalizator sam za nas zdecyduje o zastosowaniu <i>broadcast hash join</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+\n",
      "|name|age|age|\n",
      "+----+---+---+\n",
      "|Greg| 40| 20|\n",
      "|Greg| 32| 20|\n",
      "+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "newPeople.join(broadcast(spark.createDataFrame([Row(age=20, name='Greg')])), on='name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Spośród osób (`people`, `newPeople`, `people_txt`), dla których mamy informacje o zarobkach (zbiór `employees`). Ile zarabia najmłodsza osoba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  name| age|salary|\n",
      "+------+----+------+\n",
      "|Justin|19.0|  3500|\n",
      "|Justin|19.0|  3500|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols= people.columns\n",
    "union_people = people.union(people_txt.select(cols)).union(newPeople)\n",
    "min_age = union_people.select(f.min(\"age\")).collect()[0][0]\n",
    "union_people.where(union_people.age == min_age).join(employees, on=\"name\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_zad = union_people.dropna(subset=\"age\").join(employees, on=\"name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+-------+--------+\n",
      "|   name| age|salary|increas|increase|\n",
      "+-------+----+------+-------+--------+\n",
      "|   Andy|30.0|  4500|  135.0|   135.0|\n",
      "| Justin|19.0|  3500|   66.5|    66.5|\n",
      "|Michael|29.0|  3000|   87.0|    87.0|\n",
      "|   Andy|30.0|  4500|  135.0|   135.0|\n",
      "| Justin|19.0|  3500|   66.5|    66.5|\n",
      "+-------+----+------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zad = df_zad.withColumn(\"increase\", df_zad.salary * (0.001 * df_zad.age))\n",
    "df_zad.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|bonus_cost|\n",
      "+----------+\n",
      "|     490.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zad.select(f.sum(\"increase\").alias(\"bonus_cost\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Dla każdego pracownika (`employees`), dla którego mamy informacje o wieku (`people`, `newPeople`, `people_txt`). Dodaj do pensji 0.1% za każdy rok życia. Oblicz koszt takiego 'bonusu urodzinowego' dla pracodawcy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newPeople.groupBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Przez GroupedData mamy dostep do takich funkcji jak:<br>\n",
    " avg, max, min, sum, count, agg <br>\n",
    " (dla wygody, do funkcji 'agg' mamy tez dostep bezposrednio na DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(age)|\n",
      "+--------+\n",
      "|      40|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeople.groupBy().max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| name|count|\n",
      "+-----+-----+\n",
      "| Greg|    2|\n",
      "| null|    2|\n",
      "|Alice|    1|\n",
      "|Peter|    2|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeople.groupBy('name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+--------+\n",
      "| name|min_age|max_age|n_people|\n",
      "+-----+-------+-------+--------+\n",
      "| Greg|     32|     40|       2|\n",
      "| null|     33|     33|       0|\n",
      "|Alice|     24|     24|       1|\n",
      "|Peter|     32|     32|       2|\n",
      "+-----+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeople.groupBy('name').agg(f.min('age').alias('min_age'), f.max('age').alias('max_age'),\\\n",
    "                              f.count('name').alias('n_people')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----------+\n",
      "|min(age)|max(age)|count(name)|\n",
      "+--------+--------+-----------+\n",
      "|      24|      40|          5|\n",
      "+--------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPeople.agg(f.min('age'), f.max('age'), f.count('name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Ile jest unikatowych (występujących tylko 1 raz) imion w połączonych zbiorach `people`, `newPeople` oraz `people_txt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_df = union_people.groupby(\"name\").agg(f.count(\"name\").alias(\"name_count\"))\n",
    "counted_df.where(counted_df.name_count == 1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Ile lat mają osoby, których imiona występują tylko raz w połączonych zbiorach `people`, `newPeople` oraz `people_txt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----+\n",
      "| name|name_count| age|\n",
      "+-----+----------+----+\n",
      "|Alice|         1|24.0|\n",
      "| Emma|         1|35.0|\n",
      "+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counted_df.where(counted_df.name_count == 1).join(union_people, on = \"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Nowy DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "years = 10\n",
    "names = ['Alice', 'Betty', 'Chris', 'Dan', 'Greg']\n",
    "unique_names_count = len(names)\n",
    "names = sorted(names*years)\n",
    "year = [y for y in range(2000, 2000+years)]*len(names)\n",
    "starting_salary = [round(random.gauss(4000, 1000),2) for i in range(unique_names_count)]\n",
    "salary = [0 for i in range(years*unique_names_count)]\n",
    "salary[::years] = starting_salary\n",
    "for n in range(unique_names_count):\n",
    "    for y in range(years-1):\n",
    "        index = (years*n+1)+y\n",
    "        salary[index] = round(salary[index-1]*(1+random.gauss(0.1,0.09)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryHistory = spark.createDataFrame([Row(name=n, year=y, salary=s) for n,y,s in zip(names, year, salary)])\n",
    "salaryHistory = salaryHistory.filter((salaryHistory['name'] != 'Greg') | (salaryHistory['year'] != 2006))\n",
    "salaryHistory = salaryHistory.union(spark.createDataFrame([Row('Alice', 3000, 2000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----+\n",
      "| name| salary|year|\n",
      "+-----+-------+----+\n",
      "|Alice|4404.23|2000|\n",
      "|Alice|4780.34|2001|\n",
      "|Alice|4881.72|2002|\n",
      "|Alice|5280.86|2003|\n",
      "|Alice|5976.68|2004|\n",
      "|Alice|6320.14|2005|\n",
      "|Alice|6685.07|2006|\n",
      "|Alice|7816.44|2007|\n",
      "|Alice|8599.32|2008|\n",
      "|Alice|9503.99|2009|\n",
      "|Betty|4138.01|2000|\n",
      "|Betty|4404.94|2001|\n",
      "|Betty|4911.61|2002|\n",
      "|Betty|5265.17|2003|\n",
      "|Betty|5687.88|2004|\n",
      "|Betty|6033.45|2005|\n",
      "|Betty|7179.65|2006|\n",
      "|Betty|8133.84|2007|\n",
      "|Betty|8766.33|2008|\n",
      "|Betty|10516.8|2009|\n",
      "+-----+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaryHistory.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Ile razy powtarza się każde z imion w `salaryHistory`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| name|count|\n",
      "+-----+-----+\n",
      "|Chris|   10|\n",
      "| Greg|    9|\n",
      "|Betty|   10|\n",
      "|  Dan|   10|\n",
      "|Alice|   11|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaryHistory.groupBy(\"name\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Na podstawie `salaryHistory` stworz tabelę zależności średniej, minimalnej i maksymalnej pensji od roku. Posortuj lata malejąco. Pensje podaj z dokładnością do pełnych wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+-------+\n",
      "|year|   avg|   min|    max|\n",
      "+----+------+------+-------+\n",
      "|2009|8935.0|5838.0|10517.0|\n",
      "|2008|7889.0|5597.0| 8766.0|\n",
      "|2007|7497.0|5081.0| 8299.0|\n",
      "|2006|7435.0|6685.0| 8418.0|\n",
      "|2005|5997.0|4200.0| 7129.0|\n",
      "|2004|5608.0|3778.0| 6672.0|\n",
      "|2003|5283.0|3908.0| 6436.0|\n",
      "|2002|5114.0|4174.0| 5887.0|\n",
      "|2001|4515.0|4152.0| 4830.0|\n",
      "|2000|3939.0|3000.0| 4404.0|\n",
      "+----+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaryHistory.groupby(\"year\").agg(f.round(f.avg(\"salary\")).alias(\"avg\"), f.round(f.min(\"salary\")).alias(\"min\"), f.round(f.max(\"salary\")).alias(\"max\"))\\\n",
    ".orderBy(f.desc(\"year\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window functions\n",
    "**over**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Służy do obliczania agregowanych wartości w grupach definiowanych oknem (window).<br>\n",
    "Zwraca wiele rekordow (tyle ile na wejsciu w grupie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partitionBy - definiuje podział danych na okna<br>\n",
    "orderBy - definiuje sortowanie wewnątrz każdego z okien<br>\n",
    "Frame (rangeBetween/rowsBetween) - definiuje offset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**partitionBy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPeople = spark.read.parquet(data_path+'allPeople.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definicja 'okna'\n",
    "myWindowSpec = Window.partitionBy('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+\n",
      "| age|   name|nameCount|\n",
      "+----+-------+---------+\n",
      "|40.0|   Greg|        2|\n",
      "|32.0|   Greg|        2|\n",
      "|null|   null|        0|\n",
      "|33.0|   null|        0|\n",
      "|null|Michael|        2|\n",
      "|29.0|Michael|        2|\n",
      "|24.0|  Alice|        1|\n",
      "|35.0|   Emma|        1|\n",
      "|30.0|   Andy|        2|\n",
      "|30.0|   Andy|        2|\n",
      "|19.0| Justin|        2|\n",
      "|19.0| Justin|        2|\n",
      "|32.0|  Peter|        2|\n",
      "|null|  Peter|        2|\n",
      "+----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wywołanie funkcji na kazdym 'oknie'\n",
    "allPeople.withColumn('nameCount', \\\n",
    "                     f.count(allPeople['name']).over(myWindowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Do zbioru `salaryHistory` dodaj kolumnę 'avgSalaryDiff', która będzie zawierała różnicę pomiedzy pensją z danego roku, a średnią pensją osoby na przestrzeni wszytskich lat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+-------------------+-----------------+\n",
      "| name|  salary|year|       avgSalaryDiv|        avgSalary|\n",
      "+-----+--------+----+-------------------+-----------------+\n",
      "|Chris| 3601.42|2000| -3293.245000000001|6894.665000000001|\n",
      "|Chris| 4407.79|2001| -2486.875000000001|6894.665000000001|\n",
      "|Chris|  5713.7|2002| -1180.965000000001|6894.665000000001|\n",
      "|Chris|  6435.6|2003| -459.0650000000005|6894.665000000001|\n",
      "|Chris| 6671.86|2004| -222.8050000000012|6894.665000000001|\n",
      "|Chris| 7129.19|2005| 234.52499999999873|6894.665000000001|\n",
      "|Chris| 8417.84|2006| 1523.1749999999993|6894.665000000001|\n",
      "|Chris| 8155.56|2007| 1260.8949999999995|6894.665000000001|\n",
      "|Chris| 8239.77|2008| 1345.1049999999996|6894.665000000001|\n",
      "|Chris|10173.92|2009|  3279.254999999999|6894.665000000001|\n",
      "| Greg| 4226.89|2000| -323.7622222222226|4550.652222222223|\n",
      "| Greg| 4151.85|2001|-398.80222222222255|4550.652222222223|\n",
      "| Greg| 4174.36|2002|-376.29222222222324|4550.652222222223|\n",
      "| Greg| 3908.07|2003| -642.5822222222228|4550.652222222223|\n",
      "| Greg| 3778.21|2004| -772.4422222222229|4550.652222222223|\n",
      "| Greg| 4199.99|2005|-350.66222222222314|4550.652222222223|\n",
      "| Greg| 5081.34|2007|  530.6877777777772|4550.652222222223|\n",
      "| Greg| 5597.06|2008| 1046.4077777777775|4550.652222222223|\n",
      "| Greg|  5838.1|2009| 1287.4477777777774|4550.652222222223|\n",
      "|Betty| 4138.01|2000|-2365.7580000000007|6503.768000000001|\n",
      "+-----+--------+----+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myWindowSpec = Window.partitionBy(\"name\")\n",
    "salaryHistory.withColumn(\"avgSalaryDiv\", salaryHistory.salary - f.avg(salaryHistory.salary).over(myWindowSpec))\\\n",
    ".withColumn(\"avgSalary\", f.avg(salaryHistory.salary).over(myWindowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**partitionBy + orderBy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+------+\n",
      "| name|  salary|year|ranked|\n",
      "+-----+--------+----+------+\n",
      "|Chris| 3601.42|2000|     1|\n",
      "|Chris| 4407.79|2001|     2|\n",
      "|Chris|  5713.7|2002|     3|\n",
      "|Chris|  6435.6|2003|     4|\n",
      "|Chris| 6671.86|2004|     5|\n",
      "|Chris| 7129.19|2005|     6|\n",
      "|Chris| 8417.84|2006|     7|\n",
      "|Chris| 8155.56|2007|     8|\n",
      "|Chris| 8239.77|2008|     9|\n",
      "|Chris|10173.92|2009|    10|\n",
      "| Greg| 4226.89|2000|     1|\n",
      "| Greg| 4151.85|2001|     2|\n",
      "| Greg| 4174.36|2002|     3|\n",
      "| Greg| 3908.07|2003|     4|\n",
      "| Greg| 3778.21|2004|     5|\n",
      "| Greg| 4199.99|2005|     6|\n",
      "| Greg| 5081.34|2007|     7|\n",
      "| Greg| 5597.06|2008|     8|\n",
      "| Greg|  5838.1|2009|     9|\n",
      "|Betty| 4138.01|2000|     1|\n",
      "+-----+--------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# przykład: rank\n",
    "# - musimy zdefiniować dodatkowo sortowanie wewnątrz każdej z grup\n",
    "# - zwraca lp dla kolejnych rekordów posortowanych według zadanych kolumn\n",
    "windowSpec = Window.partitionBy(salaryHistory['name']).orderBy(salaryHistory['year'])\n",
    "ranked = f.rank().over(windowSpec)\n",
    "salaryHistory.withColumn('ranked', ranked).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryHistory_tmp = salaryHistory.filter(salaryHistory.name.isin('Alice', 'Greg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----+------+----------+------------+----------+\n",
      "| name| salary|year|ranked|dense_rank|percent_rank|row_number|\n",
      "+-----+-------+----+------+----------+------------+----------+\n",
      "| Greg|4226.89|2000|     1|         1|         0.0|         1|\n",
      "| Greg|4151.85|2001|     2|         2|       0.125|         2|\n",
      "| Greg|4174.36|2002|     3|         3|        0.25|         3|\n",
      "| Greg|3908.07|2003|     4|         4|       0.375|         4|\n",
      "| Greg|3778.21|2004|     5|         5|         0.5|         5|\n",
      "| Greg|4199.99|2005|     6|         6|       0.625|         6|\n",
      "| Greg|5081.34|2007|     7|         7|        0.75|         7|\n",
      "| Greg|5597.06|2008|     8|         8|       0.875|         8|\n",
      "| Greg| 5838.1|2009|     9|         9|         1.0|         9|\n",
      "|Alice|4404.23|2000|     1|         1|         0.0|         1|\n",
      "|Alice| 3000.0|2000|     1|         1|         0.0|         2|\n",
      "|Alice|4780.34|2001|     3|         2|         0.2|         3|\n",
      "|Alice|4881.72|2002|     4|         3|         0.3|         4|\n",
      "|Alice|5280.86|2003|     5|         4|         0.4|         5|\n",
      "|Alice|5976.68|2004|     6|         5|         0.5|         6|\n",
      "|Alice|6320.14|2005|     7|         6|         0.6|         7|\n",
      "|Alice|6685.07|2006|     8|         7|         0.7|         8|\n",
      "|Alice|7816.44|2007|     9|         8|         0.8|         9|\n",
      "|Alice|8599.32|2008|    10|         9|         0.9|        10|\n",
      "|Alice|9503.99|2009|    11|        10|         1.0|        11|\n",
      "+-----+-------+----+------+----------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rank, dense_rank, percent_rank, row_number\n",
    "windowSpec = Window.partitionBy('name').orderBy('year')\n",
    "ranked = (f.rank()).over(windowSpec)\n",
    "dense_rank = (f.dense_rank()).over(windowSpec)\n",
    "percent_rank = (f.percent_rank()).over(windowSpec)\n",
    "row_number = (f.row_number()).over(windowSpec)\n",
    "salaryHistory_tmp.withColumn('ranked', ranked).withColumn('dense_rank', dense_rank).\\\n",
    "withColumn('percent_rank', percent_rank).withColumn('row_number', row_number).\\\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Inne warte uwagi funkcje: <br>\n",
    "ntile, cume_dist, first, lag, lead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Dla zbioru `salaryHistory`, porównaj pensje ludzi pomiedzy najwcześniejszym i najpóźniejszym rokiem ich pracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\")\n",
    "windowSpec_desc = Window.partitionBy(\"name\").orderBy(f.desc(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+---------+--------+------------------+\n",
      "| name|  salary|year|first_sal|last_sal|       salary_diff|\n",
      "+-----+--------+----+---------+--------+------------------+\n",
      "|Chris|10173.92|2009|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 8239.77|2008|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 8155.56|2007|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 8417.84|2006|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 7129.19|2005|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 6671.86|2004|  3601.42|10173.92|           -6572.5|\n",
      "|Chris|  6435.6|2003|  3601.42|10173.92|           -6572.5|\n",
      "|Chris|  5713.7|2002|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 4407.79|2001|  3601.42|10173.92|           -6572.5|\n",
      "|Chris| 3601.42|2000|  3601.42|10173.92|           -6572.5|\n",
      "| Greg|  5838.1|2009|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 5597.06|2008|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 5081.34|2007|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 4199.99|2005|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 3778.21|2004|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 3908.07|2003|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 4174.36|2002|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 4151.85|2001|  4226.89|  5838.1|          -1611.21|\n",
      "| Greg| 4226.89|2000|  4226.89|  5838.1|          -1611.21|\n",
      "|Betty| 10516.8|2009|  4138.01| 10516.8|-6378.789999999999|\n",
      "+-----+--------+----+---------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaryHistory.withColumn(\"first_sal\", f.first(\"salary\").over(windowSpec))\\\n",
    ".withColumn(\"last_sal\", f.first(\"salary\").over(windowSpec_desc))\\\n",
    ".withColumn(\"salary_diff\", f.first(\"salary\").over(windowSpec) - f.first(\"salary\").over(windowSpec_desc)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**partitionBy + orderBy + rangeBetween/rowsBetween**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+------------------+\n",
      "| name|  salary|year|         movingAvg|\n",
      "+-----+--------+----+------------------+\n",
      "|Chris| 3601.42|2000|          4004.605|\n",
      "|Chris| 4407.79|2001| 4574.303333333333|\n",
      "|Chris|  5713.7|2002|           5519.03|\n",
      "|Chris|  6435.6|2003|           6273.72|\n",
      "|Chris| 6671.86|2004| 6745.549999999999|\n",
      "|Chris| 7129.19|2005| 7406.296666666666|\n",
      "|Chris| 8417.84|2006| 7900.863333333334|\n",
      "|Chris| 8155.56|2007| 8271.056666666667|\n",
      "|Chris| 8239.77|2008| 8856.416666666666|\n",
      "|Chris|10173.92|2009| 9206.845000000001|\n",
      "| Greg| 4226.89|2000| 4189.370000000001|\n",
      "| Greg| 4151.85|2001| 4184.366666666668|\n",
      "| Greg| 4174.36|2002| 4078.093333333333|\n",
      "| Greg| 3908.07|2003|3953.5466666666666|\n",
      "| Greg| 3778.21|2004|           3962.09|\n",
      "| Greg| 4199.99|2005|           4353.18|\n",
      "| Greg| 5081.34|2007| 4959.463333333333|\n",
      "| Greg| 5597.06|2008|            5505.5|\n",
      "| Greg|  5838.1|2009|           5717.58|\n",
      "|Betty| 4138.01|2000|          4271.475|\n",
      "+-----+--------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# przykład: średnia ruchoma\n",
    "windowSpec = Window.partitionBy(salaryHistory['name']).orderBy(salaryHistory['year'])\\\n",
    ".rowsBetween(-1,1)\n",
    "movingAvg = (f.avg(salaryHistory['salary'])).over(windowSpec)\n",
    "salaryHistory.withColumn('movingAvg', movingAvg).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+------------------+\n",
      "| name|  salary|year|         movingAvg|\n",
      "+-----+--------+----+------------------+\n",
      "|Chris| 3601.42|2000|           3601.42|\n",
      "|Chris| 4407.79|2001|          4004.605|\n",
      "|Chris|  5713.7|2002| 4574.303333333333|\n",
      "|Chris|  6435.6|2003|5039.6275000000005|\n",
      "|Chris| 6671.86|2004|5366.0740000000005|\n",
      "|Chris| 7129.19|2005| 5659.926666666667|\n",
      "|Chris| 8417.84|2006| 6053.914285714287|\n",
      "|Chris| 8155.56|2007| 6316.620000000001|\n",
      "|Chris| 8239.77|2008| 6530.303333333334|\n",
      "|Chris|10173.92|2009| 6894.665000000001|\n",
      "| Greg| 4226.89|2000|           4226.89|\n",
      "| Greg| 4151.85|2001| 4189.370000000001|\n",
      "| Greg| 4174.36|2002| 4184.366666666668|\n",
      "| Greg| 3908.07|2003|4115.2925000000005|\n",
      "| Greg| 3778.21|2004|          4047.876|\n",
      "| Greg| 4199.99|2005| 4073.228333333334|\n",
      "| Greg| 5081.34|2007| 4217.244285714286|\n",
      "| Greg| 5597.06|2008|4389.7212500000005|\n",
      "| Greg|  5838.1|2009| 4550.652222222223|\n",
      "|Betty| 4138.01|2000|           4138.01|\n",
      "+-----+--------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# przykład: średnia ze wszystkich rekordów do aktualnego włącznie\n",
    "windowSpec = Window.partitionBy(salaryHistory['name']).orderBy(salaryHistory['year']).\\\n",
    "rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
    "movingAvg = (f.avg(salaryHistory['salary'])).over(windowSpec)\n",
    "salaryHistory.withColumn('movingAvg', movingAvg).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----+------------------+\n",
      "| name| salary|year|         movingAvg|\n",
      "+-----+-------+----+------------------+\n",
      "|Alice|4404.23|2000|           4404.23|\n",
      "|Alice| 3000.0|2000|          3702.115|\n",
      "|Alice|4780.34|2001| 4061.523333333333|\n",
      "|Alice|4881.72|2002|         4266.5725|\n",
      "|Alice|5280.86|2003|           4469.43|\n",
      "|Alice|5976.68|2004| 4720.638333333333|\n",
      "|Alice|6320.14|2005| 4949.138571428572|\n",
      "|Alice|6685.07|2006|           5166.13|\n",
      "|Alice|7816.44|2007| 5460.608888888889|\n",
      "|Alice|8599.32|2008|5774.4800000000005|\n",
      "|Alice|9503.99|2009| 6113.526363636364|\n",
      "+-----+-------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaryHistory.withColumn('movingAvg', movingAvg).filter(\"name == 'Alice'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+------------------+\n",
      "| name|  salary|year|         movingAvg|\n",
      "+-----+--------+----+------------------+\n",
      "|Chris| 3601.42|2000|           3601.42|\n",
      "|Chris| 4407.79|2001|          4004.605|\n",
      "|Chris|  5713.7|2002| 4574.303333333333|\n",
      "|Chris|  6435.6|2003|5039.6275000000005|\n",
      "|Chris| 6671.86|2004|5366.0740000000005|\n",
      "|Chris| 7129.19|2005| 5659.926666666667|\n",
      "|Chris| 8417.84|2006| 6053.914285714287|\n",
      "|Chris| 8155.56|2007| 6316.620000000001|\n",
      "|Chris| 8239.77|2008| 6530.303333333334|\n",
      "|Chris|10173.92|2009| 6894.665000000001|\n",
      "| Greg| 4226.89|2000|           4226.89|\n",
      "| Greg| 4151.85|2001| 4189.370000000001|\n",
      "| Greg| 4174.36|2002| 4184.366666666668|\n",
      "| Greg| 3908.07|2003|4115.2925000000005|\n",
      "| Greg| 3778.21|2004|          4047.876|\n",
      "| Greg| 4199.99|2005| 4073.228333333334|\n",
      "| Greg| 5081.34|2007| 4217.244285714286|\n",
      "| Greg| 5597.06|2008|4389.7212500000005|\n",
      "| Greg|  5838.1|2009| 4550.652222222223|\n",
      "|Betty| 4138.01|2000|           4138.01|\n",
      "+-----+--------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# podobny efekt uzyskamy poniższym zapytaniemm. \n",
    "# Różnica: rekordy w jednej grupie (imię, rok) nie zostaną rozdzielone \n",
    "import sys\n",
    "windowSpec = Window.partitionBy(salaryHistory['name']).orderBy(salaryHistory['year']).\\\n",
    "rangeBetween(-sys.maxsize,0)\n",
    "movingAvg = (f.avg(salaryHistory['salary'])).over(windowSpec)\n",
    "salaryHistory.withColumn('movingAvg', movingAvg).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----+------------------+\n",
      "| name| salary|year|         movingAvg|\n",
      "+-----+-------+----+------------------+\n",
      "|Alice|4404.23|2000|          3702.115|\n",
      "|Alice| 3000.0|2000|          3702.115|\n",
      "|Alice|4780.34|2001| 4061.523333333333|\n",
      "|Alice|4881.72|2002|         4266.5725|\n",
      "|Alice|5280.86|2003|           4469.43|\n",
      "|Alice|5976.68|2004| 4720.638333333333|\n",
      "|Alice|6320.14|2005| 4949.138571428572|\n",
      "|Alice|6685.07|2006|           5166.13|\n",
      "|Alice|7816.44|2007| 5460.608888888889|\n",
      "|Alice|8599.32|2008|5774.4800000000005|\n",
      "|Alice|9503.99|2009| 6113.526363636364|\n",
      "+-----+-------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaryHistory.withColumn('movingAvg', movingAvg).filter(\"name == 'Alice'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################\n",
    "\n",
    "# Zadania 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Ile lat mają osoby, których imiona występują tylko raz w połączonych zbiorach `people`, `newPeople` oraz `people_txt`? Rozwiązując problem zastosuj window functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2. Czy komukolwiek obniżyła się pensja w stosunku do roku poprzedniego? <br>\n",
    "a. Ile osób było kiedykolwiek w takiej sytuacji?<br>\n",
    "b. Jaki jest rozkład częstości takich przypadków w zależności od roku?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3. Oblicz różnicę w pensjach w stosuku do <br>\n",
    "a. najwyższej pensji danej osoby<br> \n",
    "b. drugiej najwyższej pensji danej osoby<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark wspiera ANSI SQL 2003 (SQL3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby użyć zbioru danych w zapytaniu SQL musimy go najpierw zarejestrować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryHistory.createOrReplaceTempView('salaryHistory')\n",
    "# salaryHistory.registerTempTable('salaryHistorySQL') - wersja dla sparka 1.x\n",
    "# view NIE jest 'persisted in memory', to nadal nie jest akcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql('select * from salaryHistory limit 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(spark.sql('select * from salaryHistory limit 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql('select name, avg(salary) avg_sal from salaryHistory group by name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql('select name, salary, avg(salary) over (partition by name) avg_sal from salaryHistory').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"salaryHistory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDFs\n",
    "Poza funkcjami dostępnymi w module pyspark.sql.functions, można też tworzyć własne (User Defined Functions) i używać ich w zapytaniach SparkSQL <br>\n",
    "<i>Uwaga:</i> Po UDFy sięgamy w ostateczności - optymalizacja <br>\n",
    "<i>Uwaga:</i> UDF napisany w Pythonie (lub R) bedzie mial gorszy performance niż UDF napisany w Scali lub Javie. Ale możemy nasz UDF napisać w Scali/Javie i zarejestrować do użycia w Pythonie. <br>\n",
    "Blogpost o tym jak w pySparku używać UDF napisanej w scali: <br>\n",
    "https://medium.com/@ingwbaa/using-scala-udfs-in-pyspark-b70033dd69b9 <br>\n",
    "Blogpost o ulepszeniach w UDF (pandas UDF) dla pySparka od Sparku 2.3: <br>\n",
    "https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def udfPower3(value):\n",
    "    return(value**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udfPower3(3.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aby stosować zdefiniowaną funkcję, musimy ja zarejestrować. (Driver roześle funkcje do wszystkich egzekutorów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power3 = f.udf(udfPower3, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryHistory.select(power3(salaryHistory.salary)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark wspiera Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL wspiera HiveQL. <br>\n",
    "Spark SQL wspiera rownież wczytawanie/zapisywanie danych z/do Apache Hive.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiecej informacji na temat integracji z Hive:<br>\n",
    "https://spark.apache.org/docs/latest/sql-programming-guide.html#compatibility-with-apache-hive <br>\n",
    "https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
